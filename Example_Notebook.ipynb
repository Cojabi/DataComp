{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# stats\n",
    "from scipy.stats import mannwhitneyu\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "from scipy.stats import chisquare\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(paths, groupby=None, classes=None, rel_cols=None, sep=\",\"):\n",
    "    \"\"\"Will load the data and return a list of two dataframes\n",
    "    that can then be used for later comparism.\n",
    "    :param path1: Path to dataframe1\n",
    "    :param path2: Path to dataframe2. Optional if all data for comparison is in df1.\n",
    "                  Then use groupby argument\n",
    "    :param groupby: name of the column which specifies classes to compare to each other. (e.g. sampling site)\n",
    "    \"\"\"\n",
    "\n",
    "    dfs = []\n",
    "    \n",
    "    if groupby:\n",
    "        data = pd.read_csv(*paths, index_col=0, sep=sep)\n",
    "        grouping = data.groupby(groupby)\n",
    "\n",
    "        for name, grp in grouping: # split dataframe groups and create a list with all dataframes\n",
    "            df = grouping.get_group(name)[::]\n",
    "            \n",
    "            # consider all columns as relevant is no rel_cols given.\n",
    "            if rel_cols is None:\n",
    "                rel_cols = list(df)\n",
    "            # consider the relevant columns\n",
    "            dfs.append(df[rel_cols])\n",
    "\n",
    "    if len(paths) > 1:\n",
    "        for path in paths:\n",
    "            df = pd.read_csv(path, index_col=0)\n",
    "            dfs.append(df)\n",
    "\n",
    "    if classes:\n",
    "        df_names = classes\n",
    "    else:\n",
    "        df_names = [\"df\" + str(x) for x in range(1, len(dfs)+1)]\n",
    "\n",
    "    return dfs, df_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_zipper(dfs, feats=None):\n",
    "    \"\"\"create zipper containing the values of the same features per df in one list.\n",
    "    (df1_feat1, df2_feat1, df3_feat1), (df1_feat2, df2_feat2, df3_feat2),\"\"\"\n",
    "    if feats is None:\n",
    "        feats = list(dfs[0])\n",
    "\n",
    "    df_feats = []\n",
    "\n",
    "    for df in dfs:\n",
    "        df_feats.append([list(df[feat].dropna()) for feat in feats])\n",
    "\n",
    "    zip_values = zip(*df_feats)\n",
    "    zipper = dict(zip(feats, zip_values))\n",
    "    return zipper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_num_dist(zipper, feats=None):\n",
    "    \"\"\"Perform a hypothesis test to check if the distributions vary signifcantly from each other\"\"\"\n",
    "    p_values = dict()\n",
    "\n",
    "    if feats is None:\n",
    "        feats = zipper.keys()\n",
    "\n",
    "    for feat in feats:  # run through all variables\n",
    "        # initiate dict in dict for d1 vs d2, d2 vs d3 etc. per feature\n",
    "        p_values[feat] = dict() \n",
    "        \n",
    "        for i in range(len(zipper[feat]) - 1):  # select dataset1\n",
    "            for j in range(i + 1, len(zipper[feat])):  # select dataset2\n",
    "                # calculate u statistic and return p-value\n",
    "                z = mannwhitneyu(zipper[feat][i], zipper[feat][j], alternative=\"two-sided\")\n",
    "                p_values[feat][i,j] = z.pvalue\n",
    "\n",
    "    return p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs, df_names = get_data([\"/home/colin/git/DataComp/niklas_test.csv\"], groupby=\"DD01\",\n",
    "                         rel_cols=[\"IM01_01\", \"IM01_02\", \"IM01_03\", \"IM01_04\", \"IM01_05\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipper = create_zipper(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IM01_01': {(0, 1): 0.93865022890263994,\n",
       "  (0, 2): 0.33944697489739506,\n",
       "  (1, 2): 0.41130514261053808},\n",
       " 'IM01_02': {(0, 1): 0.087461416429921612,\n",
       "  (0, 2): 0.086044407605177342,\n",
       "  (1, 2): 0.10778634193843502},\n",
       " 'IM01_03': {(0, 1): 0.72883092376094039,\n",
       "  (0, 2): 0.7901927340621856,\n",
       "  (1, 2): 0.87621447991874535},\n",
       " 'IM01_04': {(0, 1): 0.026940228791894349,\n",
       "  (0, 2): 0.55080947093197574,\n",
       "  (1, 2): 0.42257809472985364},\n",
       " 'IM01_05': {(0, 1): 0.28203340227206108,\n",
       "  (0, 2): 0.15772935376007924,\n",
       "  (1, 2): 0.16420346437619715}}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_num_dist(zipper)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
